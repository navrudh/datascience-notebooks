{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPIDS NLP:\n",
    "\n",
    "### Credits:\n",
    "https://medium.com/rapids-ai/show-me-the-word-count-3146e1173801\n",
    "\n",
    "\n",
    "### Objective: Show case nlp capabilties of nvstrings+cudf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import nvcategory\n",
    "import os\n",
    "import numpy as np\n",
    "import nvtext\n",
    "import cuml\n",
    "import nvstrings\n",
    "try:\n",
    "    import nltk\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install nltk')\n",
    "    import nltk\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Data File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'data/enwiki-latest.preprocess.txt.gz'\n",
    "output_dir = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Text Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.utils\n",
    "import tqdm\n",
    "import sys\n",
    "\n",
    "ONE_GB = 10 ** 8\n",
    "\n",
    "def get_non_empty_lines(path):\n",
    "    \"\"\"\n",
    "        returns non empty lines from a list of lines\n",
    "    \"\"\"\n",
    "    chunked_output = []\n",
    "    for line in get_txt_lines(path):\n",
    "        chunked_output += [line]\n",
    "        if sys.getsizeof(chunked_output) > ONE_GB:\n",
    "            print('Chunk Size:', sys.getsizeof(chunked_output), 'bytes')\n",
    "            print('yielding')\n",
    "            yield chunked_output\n",
    "            chunked_output = []\n",
    "    yield chunked_output\n",
    "\n",
    "def get_txt_lines(path):\n",
    "    \"\"\"\n",
    "        Read text lines from gutenberg texts\n",
    "        returns (text_ls,fname_ls) where \n",
    "        text_ls= input_text_lines and fname_ls = list of fnames\n",
    "    \"\"\"\n",
    "    with gensim.utils.open(path, 'rb', encoding='utf-8') as infile:\n",
    "        for i, line in tqdm.tqdm(enumerate(infile)):\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read text lines into a cudf dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Pre-processing Pipe-Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [ '!', '\"', '#', '$', '%', '&', '(', ')', '*', '+', '-', '.', '/',  '\\\\', ':', ';', '<', '=', '>',\n",
    "           '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '\\~', '\\t','\\\\n',\"'\",\",\",'~' , 'â€”']\n",
    "\n",
    "def preprocess_text(input_strs , filters=filters):\n",
    "    \"\"\"\n",
    "        * filter punctuation\n",
    "        * to_lower\n",
    "        * remove stop words (from nltk corpus)\n",
    "        * remove multiple spaces with one\n",
    "        * remove leading spaces    \n",
    "    \"\"\"\n",
    "    \n",
    "    # filter punctuation and case conversion\n",
    "    input_strs = input_strs.str.replace_multi(filters, ' ', regex=False)\n",
    "    input_strs = input_strs.str.lower()\n",
    "        \n",
    "    # replace multiple spaces with single one and strip leading/trailing spaces\n",
    "    input_strs = input_strs.str.replace(r\"\\s+\", ' ', regex=True)\n",
    "    input_strs = input_strs.str.strip(' ')\n",
    "    \n",
    "    return input_strs\n",
    "\n",
    "def preprocess_text_df(df, text_cols=['text'], **kwargs):\n",
    "    for col in text_cols:\n",
    "        df[col] = preprocess_text(df[col], **kwargs)\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our function defined, we can execute it to preprocess the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11463627it [00:51, 216029.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 103184048 bytes\n",
      "yielding\n",
      "chunk 0 : read into GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11463627it [01:10, 216029.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 : cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11497620it [03:12, 60.60it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 : written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22921547it [04:05, 216389.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 103184048 bytes\n",
      "yielding\n",
      "chunk 1 : read into GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22921547it [04:20, 216389.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 : cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22972078it [11:00, 134.75it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 : written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34373928it [11:52, 220394.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 103184048 bytes\n",
      "yielding\n",
      "chunk 2 : read into GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34373928it [12:10, 220394.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 2 : cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34436000it [16:05, 556.84it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 2 : written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45848669it [16:57, 222182.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 103184048 bytes\n",
      "yielding\n",
      "chunk 3 : read into GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45848669it [17:10, 222182.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 3 : cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45902061it [21:45, 256.03it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 3 : written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57311390it [22:37, 225728.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 103184048 bytes\n",
      "yielding\n",
      "chunk 4 : read into GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57311390it [22:50, 225728.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 4 : cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57370255it [34:13, 127.22it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 4 : written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68771002it [35:04, 221624.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 103184048 bytes\n",
      "yielding\n",
      "chunk 5 : read into GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68771002it [35:20, 221624.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 5 : cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68833389it [39:22, 481.84it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 5 : written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80232391it [40:13, 222966.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 103184048 bytes\n",
      "yielding\n",
      "chunk 6 : read into GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80232391it [40:30, 222966.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 6 : cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80296891it [44:45, 543.15it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 6 : written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91703873it [45:37, 213736.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 103184048 bytes\n",
      "yielding\n",
      "chunk 7 : read into GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91703873it [45:50, 213736.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 7 : cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91762305it [51:31, 291.52it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 7 : written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103172123it [52:22, 220283.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 103184048 bytes\n",
      "yielding\n",
      "chunk 8 : read into GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103172123it [52:40, 220283.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 8 : cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103226511it [56:32, 321.48it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 8 : written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114628358it [57:24, 218358.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 103184048 bytes\n",
      "yielding\n",
      "chunk 9 : read into GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114628358it [57:40, 218358.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 9 : cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114691982it [1:05:28, 287.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 9 : written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121169182it [1:05:58, 30613.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 10 : read into GPU\n",
      "chunk 10 : cleaned\n",
      "chunk 10 : written to file\n"
     ]
    }
   ],
   "source": [
    "for i, txt_ls in enumerate(get_non_empty_lines(data_file)):\n",
    "    df = cudf.DataFrame()\n",
    "\n",
    "    df['text'] = nvstrings.to_device(txt_ls)\n",
    "    print('chunk',i,': read into GPU')\n",
    "\n",
    "    df = preprocess_text_df(df)\n",
    "    print('chunk',i,': cleaned')\n",
    "\n",
    "    df.to_csv(path=data_file+'.clean.'+str(i), columns=['text'], header=False, index=False)\n",
    "    print('chunk',i,': written to file')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:word-embeddings]",
   "language": "python",
   "name": "conda-env-word-embeddings-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
